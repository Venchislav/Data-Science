{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOuFXLxoRiE/Z3QHii/t+UA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Venchislav/Data-Science/blob/main/Statube.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GETTING COMMENTS OF VIDEO BY YOUTUBE API**"
      ],
      "metadata": {
        "id": "SvX3ZJaQoZNq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install apiclient"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CU5kUxnXabL5",
        "outputId": "69ffdbfd-78d2-451e-9f3e-6a65c55b496e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: apiclient in /usr/local/lib/python3.10/dist-packages (1.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from apiclient) (2.0.7)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from apiclient) (2023.7.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from info import KEY"
      ],
      "metadata": {
        "id": "Kz8jArlmji_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from googleapiclient.discovery import build\n",
        "\n",
        "api_key = KEY\n",
        "\n",
        "coms = []\n",
        "sussy_baka = 0\n",
        "def video_comments(video_id):\n",
        "    global sussy_baka\n",
        "\n",
        "\n",
        "    # creating youtube resource object\n",
        "    youtube = build('youtube', 'v3',\n",
        "                    developerKey=api_key)\n",
        "\n",
        "    # retrieve youtube video results\n",
        "    video_response=youtube.commentThreads().list(\n",
        "    part='snippet,replies',\n",
        "    videoId=video_id\n",
        "    ).execute()\n",
        "\n",
        "    # iterate video response\n",
        "    while video_response:\n",
        "\n",
        "        # extracting required info\n",
        "        # from each result object\n",
        "        for item in video_response['items']:\n",
        "\n",
        "            # Extracting comments\n",
        "            comment = item['snippet']['topLevelComment']['snippet']['textDisplay']\n",
        "            coms.append(comment)\n",
        "\n",
        "\n",
        "\n",
        "            if sussy_baka < 10:\n",
        "              print(comment,  end ='\\n')\n",
        "            sussy_baka += 1\n",
        "\n",
        "        if sussy_baka > 50_000:\n",
        "          break\n",
        "        # Again repeat\n",
        "        if 'nextPageToken' in video_response:\n",
        "            video_response = youtube.commentThreads().list(\n",
        "                    part = 'snippet,replies',\n",
        "                    videoId = video_id,\n",
        "                      pageToken = video_response['nextPageToken']\n",
        "                ).execute()\n",
        "        else:\n",
        "            break\n",
        "\n",
        "# Enter video id\n",
        "video_id = \"lEtP2nTsfM8\"\n",
        "\n",
        "# Call function\n",
        "video_comments(video_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 464
        },
        "id": "ZKMoH8d2gJIz",
        "outputId": "9299f5c9-2842-49bf-d98b-e6a93764b74b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:googleapiclient.http:Encountered 403 Forbidden with reason \"quotaExceeded\"\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "HttpError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHttpError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-174-8e80cfdab7eb>\u001b[0m in \u001b[0;36m<cell line: 54>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;31m# Call function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m \u001b[0mvideo_comments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-174-8e80cfdab7eb>\u001b[0m in \u001b[0;36mvideo_comments\u001b[0;34m(video_id)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mpart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'snippet,replies'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mvideoId\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvideo_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     ).execute()\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# iterate video response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/googleapiclient/_helpers.py\u001b[0m in \u001b[0;36mpositional_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mpositional_parameters_enforcement\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mPOSITIONAL_WARNING\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpositional_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/googleapiclient/http.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, http, num_retries)\u001b[0m\n\u001b[1;32m    936\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 938\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHttpError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muri\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    939\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostproc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHttpError\u001b[0m: <HttpError 403 when requesting https://youtube.googleapis.com/youtube/v3/commentThreads?part=snippet%2Creplies&videoId=lEtP2nTsfM8&key=AIzaSyDGcKeQRU7YR2i3CwlkrsWC0LMX916ygAU&alt=json returned \"The request cannot be completed because you have exceeded your <a href=\"/youtube/v3/getting-started#quota\">quota</a>.\". Details: \"[{'message': 'The request cannot be completed because you have exceeded your <a href=\"/youtube/v3/getting-started#quota\">quota</a>.', 'domain': 'youtube.quota', 'reason': 'quotaExceeded'}]\">"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(coms)"
      ],
      "metadata": {
        "id": "oyfUE-JQnG52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **HERE ML PART BEGINS**"
      ],
      "metadata": {
        "id": "WFtTz8zmohPn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "-QVazU9-oHJl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/sample_data/youtoxic_english_1000.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "kXidxh21pvZ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(['CommentId', 'VideoId', 'IsThreat',\t'IsAbusive', 'IsProvocative',\t'IsObscene',\t'IsHatespeech',\t'IsRacist',\t'IsNationalist',\t'IsSexist',\t'IsHomophobic',\t'IsReligiousHate',\t'IsRadicalism'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "vK4x5zejqO37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "t1ByHarRqvur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['IsToxic'] = df['IsToxic'].apply(lambda x: 1 if x else 0)"
      ],
      "metadata": {
        "id": "UWx6eM79rG86"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "LEegNCyYrPmZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Text'] = df['Text'].apply(lambda x: x.strip())"
      ],
      "metadata": {
        "id": "NEz0S8z6rSQS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "zoVH56WfrquK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, test_df = train_test_split(df, test_size=300)"
      ],
      "metadata": {
        "id": "sd3fu5J7ya27"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import nltk\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import SnowballStemmer\n",
        "nltk.download('punkt')\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import precision_score, recall_score, precision_recall_curve\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "lIuNoknnsIHu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "_0iIWYXAyORK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "snowball = SnowballStemmer(language=\"english\")\n",
        "stop_words = stopwords.words(\"english\")\n",
        "\n",
        "def tokenize_sentence(sentence: str, remove_sw: bool = True):\n",
        "    tokens = word_tokenize(sentence, language=\"english\")\n",
        "    tokens = [i for i in tokens if i not in string.punctuation]\n",
        "    if remove_sw:\n",
        "        tokens = [i for i in tokens if i not in stop_words]\n",
        "    tokens = [snowball.stem(i) for i in tokens]\n",
        "    return tokens"
      ],
      "metadata": {
        "id": "cCS28ts4ynLI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenize_sentence(train_df.iloc[0]['Text'])"
      ],
      "metadata": {
        "id": "ku3lSMYEyulO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer(tokenizer=lambda x: tokenize_sentence(x, remove_sw=True))\n",
        "\n",
        "features = vectorizer.fit_transform(train_df['Text'])"
      ],
      "metadata": {
        "id": "Ji7lP8ZqzBn_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression(random_state=0)\n",
        "model.fit(features, train_df['Text'])"
      ],
      "metadata": {
        "id": "TNrClvxuzRiy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression(random_state=0)\n",
        "model.fit(features, train_df['IsToxic'])"
      ],
      "metadata": {
        "id": "rFey5RQ-zbdR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(features[0])"
      ],
      "metadata": {
        "id": "1ASs-7Hd0XC5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df[\"Text\"].iloc[0]"
      ],
      "metadata": {
        "id": "r_xkSmqT0bb8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_pipeline = Pipeline([\n",
        "    (\"vectorizer\", TfidfVectorizer(tokenizer=lambda x: tokenize_sentence(x, remove_sw=True))),\n",
        "    (\"model\", LogisticRegression(random_state=0))\n",
        "]\n",
        ")"
      ],
      "metadata": {
        "id": "PWrFbb2C0evC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_pipeline.fit(train_df['Text'], train_df['IsToxic'])"
      ],
      "metadata": {
        "id": "Vnm3OXfo0jKL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_pipeline.predict(['Breaking Bad [NG+] (Alternate Ending)'])"
      ],
      "metadata": {
        "id": "ZKKXHfUA08I4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coms = [x.strip() for x in coms]"
      ],
      "metadata": {
        "id": "zO1S7_bg1mlX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "toxic = 0\n",
        "normal = 0\n",
        "for i in coms:\n",
        "  if model_pipeline.predict([i]) == [1]:\n",
        "    toxic += 1\n",
        "  else:\n",
        "    normal += 1\n"
      ],
      "metadata": {
        "id": "nEo3rG_o11Yw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.pie([toxic, normal], labels=['Toxic', 'Usual'], autopct='%.1f%%')"
      ],
      "metadata": {
        "id": "NL-cqK8F2msP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}